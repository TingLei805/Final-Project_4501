{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0750458",
   "metadata": {},
   "source": [
    "# NYC Apartment Search\n",
    "\n",
    "### Group Members: Ting Lei, Diwen Shi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf11fa0-4684-4f5e-8048-0f4cc5f4f243",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d51392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f869ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = \"data\"\n",
    "ZIPCODE_DATA_FILE = DATA_DIR + \"/nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR + \"/zillow_rent_data.csv\"\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"Swia3cwdHIaSCmkBJBrjXKYaf\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/\"\n",
    "NYC_DATA_311 = BASE_NYC_DATA_URL + f\"resource/erm2-nwe9.csv?$$app_token={NYC_DATA_APP_TOKEN}&$select=created_date,incident_zip,latitude,longitude,complaint_type&$where=created_date BETWEEN '2022-10-01T00:00:00.000' AND '2023-09-30T23:59:59.999'&$limit=999999999\"\n",
    "NYC_DATA_TREES = BASE_NYC_DATA_URL + f\"api/views/5rq2-4hqu/rows.csv?$$app_token={NYC_DATA_APP_TOKEN}\"\n",
    "NYC_DATA_311_FILE = DATA_DIR + \"/311.csv\"\n",
    "NYC_DATA_TREE_FILE = DATA_DIR + \"/tree.csv\"\n",
    "\n",
    "\n",
    "DB_NAME = \"DataEda\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PW = \"postgres\" # password\n",
    "DB_URL = f\"postgresql+psycopg2://{DB_USER}:{DB_PW}@localhost:5432/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = \"queries\"\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(QUERY_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464a7d95",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151b785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_311_tree_data():\n",
    "    \"\"\"\n",
    "    This is a function to download data programmatically.\n",
    "\n",
    "    If 311/tree file directory does not exist, this function will create a new file \n",
    "    under this directory using request method.\n",
    "\n",
    "    Parameters:\n",
    "    Does not have any parameters.\n",
    "\n",
    "    Returns:\n",
    "    No returns but simply generate two text files containing data.\n",
    "    \"\"\"\n",
    "    print(\"downloading\")\n",
    "    if not os.path.exists(NYC_DATA_311_FILE):\n",
    "        response311 = requests.get(NYC_DATA_311)\n",
    "        if response311.status_code == 200:\n",
    "            with open(NYC_DATA_311_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(response311.text)\n",
    "        else:\n",
    "            raise Exception(\"Fail\")\n",
    "\n",
    "    if not os.path.exists(NYC_DATA_TREE_FILE):\n",
    "        responsetree = requests.get(NYC_DATA_TREES)\n",
    "        if responsetree.status_code == 200:\n",
    "            with open(NYC_DATA_TREE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(responsetree.text)\n",
    "        else:\n",
    "            raise Exception(\"Fail\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d2a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_311_tree_data():\n",
    "    \"\"\"\n",
    "    This is a function to read data into pandas dataframe.\n",
    "\n",
    "    Use a default pandas index and specify incident_zip column as string type, also drop\n",
    "    all rows that contain nan data and rename all imperative columns.\n",
    "\n",
    "    Parameters:\n",
    "    Does not have any parameters.\n",
    "\n",
    "    Returns:\n",
    "    311 and tree census dataframes.\n",
    "    \"\"\"\n",
    "    data_311 = pd.read_csv(NYC_DATA_311_FILE, index_col=None, dtype={\"incident_zip\":str}) \\\n",
    "            .dropna() \\\n",
    "            .rename(columns={\"created_date\": \"Time\", \"incident_zip\": \"ZipCode\", \"latitude\": \"Latitude\", \"longitude\": \"Longitude\", \"complaint_type\":\"ComplaintType\"})\n",
    "\n",
    "    data_tree = pd.read_csv(NYC_DATA_TREE_FILE, index_col=None, dtype={\"zipcode\": str}) \\\n",
    "        [[\"tree_id\", \"zipcode\", \"Latitude\", \"longitude\", \"spc_latin\", \"status\", \"health\"]] \\\n",
    "        .rename(columns={\"tree_id\": \"ID\", \"zipcode\": \"ZipCode\", \"longitude\": \"Longitude\", \"spc_latin\": \"Species\", \"status\": \"Status\", \"health\": \"Health\"}) \\\n",
    "        .dropna()\n",
    "\n",
    "    return data_311, data_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fadfdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile):\n",
    "    \"\"\"a function of which paramter is the file directory of zipcode datafile and returns a geometry datafile\"\"\"\n",
    "    nyc_shp = gpd.read_file(zipcode_datafile).to_crs(epsg=4326)\n",
    "    return nyc_shp\n",
    "\n",
    "def load_and_clean_zillow_data(zl_file):\n",
    "    \"\"\"a function of which paramter is the file directory of zillow data and returns a datafile\"\"\"\n",
    "    zillow = pd.read_csv(zl_file, index_col=None)\n",
    "    def expand_row(row):\n",
    "        value = row[9:]\n",
    "        df = pd.DataFrame({\"Time\": value.index, \"Rent\": value.values, \"ZipCode\": row[\"RegionName\"]})\n",
    "        return df\n",
    "    zillow = pd.concat(zillow.apply(expand_row, axis=1).tolist(), ignore_index=True).dropna()\n",
    "    return zillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7638d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    download_311_tree_data()\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    geodf_311_data,geodf_tree_data = load_311_tree_data()\n",
    "    df_zillow_data = load_and_clean_zillow_data(zl_file=ZILLOW_DATA_FILE)\n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        df_zillow_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa16ec99",
   "metadata": {},
   "source": [
    "_Downloading all the data we need in subsequent tasks_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbb7cb8",
   "metadata": {},
   "source": [
    "_Show basic info about each dataframe and show first 5 entries about each dataframe_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c0e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a95b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd765b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df43fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b1774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61282a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55175f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "def setup_new_postgis_database(username, db_name):\n",
    "    \"\"\"Using SQL to create a new database and enable postgis extension\"\"\"\n",
    "    try:\n",
    "        connection = psycopg2.connect(user=username,password=DB_PW)\n",
    "        connection.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "\n",
    "        with connection.cursor() as cursor:\n",
    "            create_db_query = sql.SQL(\"CREATE DATABASE {}\").format(sql.Identifier(db_name))\n",
    "            cursor.execute(create_db_query)\n",
    "\n",
    "        print(f\"Database '{db_name}' created successfully!\")\n",
    "\n",
    "        connection.close()\n",
    "        connection = psycopg2.connect(user=username, password=DB_PW,database=db_name)\n",
    "        connection.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        with connection.cursor() as cursor:\n",
    "            create_extension_query = \"CREATE EXTENSION IF NOT EXISTS postgis;\"\n",
    "            cursor.execute(create_extension_query)\n",
    "\n",
    "        print(\"PostGIS extension enabled successfully!\")\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(f\"Error while setting up database: {error}\")\n",
    "\n",
    "    finally:\n",
    "        if connection:\n",
    "            connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_new_postgis_database(DB_USER, DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIPCODE_SCHEMA = \"\"\"\n",
    "DROP TABLE IF EXISTS \"public\".\"ZipCode\";\n",
    "CREATE TABLE \"public\".\"ZipCode\" (\n",
    "  \"ZIPCODE\" text COLLATE \"pg_catalog\".\"default\",\n",
    "  \"BLDGZIP\" text COLLATE \"pg_catalog\".\"default\",\n",
    "  \"PO_NAME\" text COLLATE \"pg_catalog\".\"default\",\n",
    "  \"POPULATION\" float8,\n",
    "  \"AREA\" float8,\n",
    "  \"STATE\" text COLLATE \"pg_catalog\".\"default\",\n",
    "  \"COUNTY\" text COLLATE \"pg_catalog\".\"default\",\n",
    "  \"ST_FIPS\" text COLLATE \"pg_catalog\".\"default\",\n",
    "  \"CTY_FIPS\" text COLLATE \"pg_catalog\".\"default\",\n",
    "  \"URL\" text COLLATE \"pg_catalog\".\"default\",\n",
    "  \"SHAPE_AREA\" float8,\n",
    "  \"SHAPE_LEN\" float8,\n",
    "  \"geometry\" \"public\".\"geometry\"\n",
    ")\n",
    ";\n",
    "\n",
    "CREATE INDEX \"idx_ZipCode_geometry\" ON \"public\".\"ZipCode\" USING gist (\n",
    "  \"geometry\" \"public\".\"gist_geometry_ops_2d\"\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "NYC_311_SCHEMA = \"\"\"\n",
    "DROP TABLE IF EXISTS \"public\".\"NYC_311\";\n",
    "CREATE TABLE \"public\".\"NYC_311\" (\n",
    "  \"ZipCode\" varchar(10) COLLATE \"pg_catalog\".\"default\" NOT NULL,\n",
    "  \"Time\" date NOT NULL,\n",
    "  \"Latitude\" float8,\n",
    "  \"Longitude\" float8,\n",
    "  \"ComplaintType\" varchar(255) COLLATE \"pg_catalog\".\"default\"\n",
    ")\n",
    ";\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "NYC_TREE_SCHEMA = \"\"\"\n",
    "DROP TABLE IF EXISTS \"public\".\"NYC_Tree\";\n",
    "CREATE TABLE \"public\".\"NYC_Tree\" (\n",
    "  \"ID\" int8 NOT NULL,\n",
    "  \"ZipCode\" varchar(10) COLLATE \"pg_catalog\".\"default\",\n",
    "  \"Longitude\" float8,\n",
    "  \"Latitude\" float8,\n",
    "  \"Species\" varchar(255) COLLATE \"pg_catalog\".\"default\",\n",
    "  \"Status\" varchar(255) COLLATE \"pg_catalog\".\"default\",\n",
    "  \"Health\" varchar(255) COLLATE \"pg_catalog\".\"default\"\n",
    ")\n",
    ";\n",
    "\n",
    "ALTER TABLE \"public\".\"NYC_Tree\" ADD CONSTRAINT \"Tree_pkey\" PRIMARY KEY (\"ID\");\n",
    "\"\"\"\n",
    "\n",
    "ZILLOW_SCHEMA = \"\"\"\n",
    "DROP TABLE IF EXISTS \"public\".\"Zillow\";\n",
    "CREATE TABLE \"public\".\"Zillow\" (\n",
    "  \"ZipCode\" varchar(10) COLLATE \"pg_catalog\".\"default\" NOT NULL,\n",
    "  \"Time\" date NOT NULL,\n",
    "  \"Rent\" float4\n",
    ")\n",
    ";\n",
    "\n",
    "ALTER TABLE \"public\".\"Zillow\" ADD CONSTRAINT \"Rent_pkey\" PRIMARY KEY (\"ZipCode\", \"Time\");\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DB_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(ZIPCODE_SCHEMA)\n",
    "    f.write(NYC_311_SCHEMA)\n",
    "    f.write(NYC_TREE_SCHEMA)\n",
    "    f.write(ZILLOW_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "with engine.connect() as connection:\n",
    "    with open(\"schema.sql\", 'r') as file:\n",
    "        sql_script = text(file.read())\n",
    "        connection.execute(sql_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Data to Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablename_to_dataframe = {\n",
    "    \"ZipCode\": geodf_zipcode_data,\n",
    "    \"NYC_311\": geodf_311_data,\n",
    "    \"NYC_Tree\": geodf_tree_data,\n",
    "    \"Zillow\": df_zillow_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data.to_postgis('ZipCode', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.to_sql('NYC_Tree', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.to_sql('NYC_311', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.to_sql('Zillow', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95edc278",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475ce5ad",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a58fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    with open(outfile, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b274ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = QUERY_DIR + \"/Q1.sql\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "SELECT\n",
    "    \"ZipCode\" AS zip_code,\n",
    "    COUNT(*) AS number_of_311_complaints\n",
    "FROM\n",
    "    \"NYC_311\"\n",
    "WHERE\n",
    "    \"Time\" BETWEEN '2022-10-01 00:00:00' AND '2023-09-30 23:59:59'\n",
    "GROUP BY\n",
    "    \"ZipCode\"\n",
    "ORDER BY\n",
    "    number_of_311_complaints DESC;\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_1))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79afadc5",
   "metadata": {},
   "source": [
    "### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66909c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_2_FILENAME = QUERY_DIR + \"/Q2.sql\"\n",
    "\n",
    "QUERY_2 = \"\"\"\n",
    "SELECT\n",
    "    \"ZipCode\" AS zip_code,\n",
    "    COUNT(*) AS top_tree_count\n",
    "FROM\n",
    "    \"NYC_Tree\"\n",
    "GROUP BY\n",
    "    \"ZipCode\"\n",
    "ORDER BY\n",
    "    top_tree_count DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_2))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "write_query_to_file(QUERY_2, QUERY_2_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bced8d31",
   "metadata": {},
   "source": [
    "### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d83435",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_3_FILENAME = QUERY_DIR + \"/Q3.sql\"\n",
    "\n",
    "QUERY_3 = \"\"\"\n",
    "SELECT\n",
    "    t.zip_code,\n",
    "    ROUND(z.\"Rent\"::numeric, 2) as rent,\n",
    "    t.tree_count\n",
    "FROM\n",
    "    \"Zillow\" as z\n",
    "RIGHT JOIN (\n",
    "    SELECT\n",
    "        \"ZipCode\" AS zip_code,\n",
    "        COUNT(*) AS tree_count\n",
    "    FROM\n",
    "        \"NYC_Tree\"\n",
    "    GROUP BY\n",
    "        \"ZipCode\"\n",
    "    ORDER BY\n",
    "        tree_count DESC\n",
    "    LIMIT 10\n",
    ") AS t ON z.\"ZipCode\" = t.zip_code\n",
    "WHERE\n",
    "    z.\"Time\" = '2023-08-31';\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_3))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "write_query_to_file(QUERY_3, QUERY_3_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7693da4",
   "metadata": {},
   "source": [
    "### Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c3118",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_4_FILENAME = QUERY_DIR + \"/Q4.sql\"\n",
    "\n",
    "QUERY_4 = \"\"\"\n",
    "WITH\n",
    "  zillow_ranked_rent AS (\n",
    "    SELECT\n",
    "        \"Rent\",\n",
    "        \"ZipCode\",\n",
    "        ROW_NUMBER() OVER (ORDER BY \"Rent\") as rent_row_num_asc,\n",
    "        ROW_NUMBER() OVER (ORDER BY \"Rent\" DESC) as rent_row_num_desc\n",
    "    FROM\n",
    "        \"Zillow\"\n",
    "    WHERE\n",
    "        \"Time\" = '2023-01-31'\n",
    "  ),\n",
    "  tree_count AS (\n",
    "    SELECT\n",
    "        \"ZipCode\",\n",
    "        COUNT(*) AS tree_count\n",
    "    FROM\n",
    "        \"NYC_Tree\"\n",
    "    GROUP BY\n",
    "        \"ZipCode\"\n",
    "  ),\n",
    "  complaint_count AS (\n",
    "    SELECT\n",
    "        \"ZipCode\",\n",
    "        COUNT(*) AS complaint_count\n",
    "    FROM\n",
    "        \"NYC_311\"\n",
    "    GROUP BY\n",
    "        \"ZipCode\"\n",
    "  )\n",
    "\n",
    "SELECT a.\"Rent\", a.\"ZipCode\", b.tree_count, c.complaint_count\n",
    "FROM (\n",
    "    SELECT \"Rent\", \"ZipCode\"\n",
    "    FROM zillow_ranked_rent\n",
    "    WHERE\n",
    "        rent_row_num_asc <= 5\n",
    "        OR rent_row_num_desc <= 5\n",
    ") AS a\n",
    "LEFT JOIN tree_count AS b ON a.\"ZipCode\" = b.\"ZipCode\"\n",
    "LEFT JOIN complaint_count AS c ON a.\"ZipCode\" = c.\"ZipCode\";\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_4))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "write_query_to_file(QUERY_4, QUERY_4_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd202179",
   "metadata": {},
   "source": [
    "### Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b39166",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_5_FILENAME = QUERY_DIR + \"/Q5.sql\"\n",
    "\n",
    "QUERY_5 = \"\"\"\n",
    "SELECT\n",
    "    z.\"ZIPCODE\" as zip_code,\n",
    "    COUNT(*) as tree_count\n",
    "FROM\n",
    "    \"NYC_Tree\" t\n",
    "JOIN\n",
    "    \"ZipCode\" z ON ST_Within(ST_SetSRID(ST_MakePoint(t.\"Longitude\", t.\"Latitude\"), 4326), z.geometry)\n",
    "GROUP BY z.\"ZIPCODE\"\n",
    "ORDER BY tree_count DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_5))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "write_query_to_file(QUERY_5, QUERY_5_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8918cda",
   "metadata": {},
   "source": [
    "### Query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ff06e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_6_FILENAME = QUERY_DIR + \"/Q6.sql\"\n",
    "\n",
    "QUERY_6 = \"\"\"\n",
    "SELECT\n",
    "    \"ID\",\n",
    "    \"ZipCode\",\n",
    "    \"Species\",\n",
    "    \"Status\",\n",
    "    \"Health\",\n",
    "    CONCAT(\"Latitude\", ', ', \"Longitude\") AS LatLng\n",
    "FROM\n",
    "    \"NYC_Tree\"\n",
    "WHERE\n",
    "    ST_DWithin(\n",
    "        ST_MakePoint(-73.96253174434912, 40.80737875669467)::geography,\n",
    "        ST_MakePoint(\"Longitude\", \"Latitude\")::geography,\n",
    "        0.5 * 1609.34\n",
    "    );\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(db.text(QUERY_6))\n",
    "    for row in result:\n",
    "        print(row)\n",
    "write_query_to_file(QUERY_6, QUERY_6_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    dataframe.plot(x=\"time\", y=\"complaint_count\",kind='line', color='green', ax=axes)\n",
    "    axes.set_title('Complaints per Day')\n",
    "    axes.set_xlabel('Date')\n",
    "    axes.set_ylabel('Complaints')\n",
    "    figure.show()\n",
    "\n",
    "def get_data_for_visual_1():\n",
    "    # Define the SQL query\n",
    "    query = \"\"\"\n",
    "        SELECT\n",
    "            \"Time\" AS time,\n",
    "            COUNT(*) AS complaint_count\n",
    "        FROM\n",
    "            \"public\".\"NYC_311\"\n",
    "        WHERE\n",
    "            \"Time\" BETWEEN '2022-10-01' AND '2023-09-30'\n",
    "        GROUP BY\n",
    "            \"Time\";\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visual_2(dataframe):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(dataframe[\"ComplaintType\"], dataframe[\"complaint_count\"], color='green')\n",
    "    plt.title('Top 10 Complaints in ZipCode 10027')\n",
    "    plt.xlabel('Complaint Type')\n",
    "    plt.ylabel('Complaint Count')\n",
    "    plt.xticks(rotation=-45, ha='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_data_for_visual_2():\n",
    "    # Define the SQL query\n",
    "    query = \"\"\"\n",
    "        SELECT\n",
    "            \"ComplaintType\",\n",
    "            COUNT(*) AS complaint_count\n",
    "        FROM\n",
    "            \"public\".\"NYC_311\"\n",
    "        WHERE\n",
    "            \"ZipCode\" = '10027'\n",
    "            AND \"Time\" BETWEEN '2018-10-01' AND '2023-09-30'\n",
    "        GROUP BY\n",
    "            \"ComplaintType\"\n",
    "        ORDER BY\n",
    "            complaint_count DESC\n",
    "        LIMIT 10\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql_query(query, engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_2()\n",
    "plot_visual_2(some_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_3():\n",
    "    # Define the SQL queries\n",
    "    query_rent = \"\"\"\n",
    "        SELECT\n",
    "            \"ZipCode\",\n",
    "            AVG(\"Rent\") AS avg_rent\n",
    "        FROM\n",
    "            \"public\".\"Zillow\"\n",
    "        WHERE\n",
    "            \"Time\" BETWEEN '2015-01-01' AND '2023-09-30'\n",
    "        GROUP BY\n",
    "            \"ZipCode\"\n",
    "    \"\"\"\n",
    "\n",
    "    query_trees = \"\"\"\n",
    "        SELECT\n",
    "            \"ZipCode\",\n",
    "            COUNT(*) AS num_trees\n",
    "        FROM\n",
    "            \"public\".\"NYC_Tree\"\n",
    "        GROUP BY\n",
    "            \"ZipCode\"\n",
    "    \"\"\"\n",
    "\n",
    "    query_complaints = \"\"\"\n",
    "        SELECT\n",
    "            \"ZipCode\",\n",
    "            COUNT(*) AS num_complaints\n",
    "        FROM\n",
    "            \"public\".\"NYC_311\"\n",
    "        WHERE\n",
    "            \"Time\" BETWEEN '2015-01-01' AND '2023-09-30'\n",
    "        GROUP BY\n",
    "            \"ZipCode\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Use Pandas to read the query results\n",
    "    df_rent = pd.read_sql_query(query_rent, engine)\n",
    "    df_trees = pd.read_sql_query(query_trees, engine)\n",
    "    df_complaints = pd.read_sql_query(query_complaints, engine)\n",
    "\n",
    "    # Merge the dataframes on ZipCode\n",
    "    df_combined = pd.merge(df_rent, df_trees, on=\"ZipCode\", how=\"outer\")\n",
    "    df_combined = pd.merge(df_combined, df_complaints, on=\"ZipCode\", how=\"outer\")\n",
    "\n",
    "    return df_combined\n",
    "\n",
    "def plot_visual_3(dataframe):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "    sns.scatterplot(data=dataframe, y=\"num_trees\", x=\"avg_rent\", hue=\"num_trees\", ax=axes, palette=\"coolwarm\", marker='o', s=50, alpha=0.8, edgecolor='black')\n",
    "    sns.scatterplot(data=dataframe, y=\"num_complaints\", x=\"avg_rent\", hue=\"num_complaints\", ax=axes, palette=\"plasma\", marker='s', s=50, alpha=0.8, edgecolor='black')\n",
    "    axes.set_xlabel('Average Rent')\n",
    "\n",
    "    axes.set_ylabel('Count of Tree or Complaints')\n",
    "\n",
    "    axes.legend(title='Trees Count', loc='upper right')\n",
    "    axes.legend(title='Complaints Count', loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_3()\n",
    "plot_visual_3(some_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visual_4(engine, start_date, end_date):\n",
    "    # Query for average rent\n",
    "    query_rent = f\"\"\"\n",
    "        SELECT\n",
    "            \"ZipCode\",\n",
    "            AVG(\"Rent\") AS avg_rent\n",
    "        FROM\n",
    "            \"public\".\"Zillow\"\n",
    "        WHERE\n",
    "            \"Time\" = '{end_date}'\n",
    "        GROUP BY\n",
    "            \"ZipCode\"\n",
    "    \"\"\"\n",
    "    df_rent = pd.read_sql_query(query_rent, engine)\n",
    "\n",
    "    # Query for complaints\n",
    "    query_complaints = f\"\"\"\n",
    "        SELECT\n",
    "            \"ZipCode\",\n",
    "            COUNT(*) AS num_complaints\n",
    "        FROM\n",
    "            \"public\".\"NYC_311\"\n",
    "        WHERE\n",
    "            \"Time\" BETWEEN '{start_date}' AND '{end_date}'\n",
    "        GROUP BY\n",
    "            \"ZipCode\"\n",
    "    \"\"\"\n",
    "    df_complaints = pd.read_sql_query(query_complaints, engine)\n",
    "    df_combined = pd.merge(df_rent, df_complaints, on=\"ZipCode\", how=\"inner\")\n",
    "\n",
    "    bins = list(range(0, int(df_combined['avg_rent'].max()) + 1001, 1000))\n",
    "    df_combined['rent_bin'] = pd.cut(df_combined['avg_rent'], bins, labels=[f'${i}-{i+1000}' for i in range(0, int(df_combined['avg_rent'].max()), 1000)])\n",
    "\n",
    "    # Plot boxplot with different color and style\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.boxplot(data=df_combined, x='rent_bin', y='num_complaints', color='skyblue', linewidth=2)\n",
    "    plt.title(f'Boxplot of 311 Complaints vs. Average Rent ({end_date})')\n",
    "    plt.xlabel(f'Average Rent in {end_date}')\n",
    "    plt.ylabel('Number of 311 Complaints')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_visual_4(engine, '2022-10-01', '2023-09-30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visual_5(engine, center_latitude, center_longitude, radius, start_date, end_date):\n",
    "    # SQL query for 311 complaints within a specified radius\n",
    "    query_complaints = f\"\"\"\n",
    "        SELECT\n",
    "            \"ZipCode\",\n",
    "            \"Time\",\n",
    "            \"Latitude\",\n",
    "            \"Longitude\"\n",
    "        FROM\n",
    "            \"public\".\"NYC_311\"\n",
    "        WHERE\n",
    "            ST_DWithin(\n",
    "                ST_MakePoint({center_longitude}, {center_latitude})::geography,\n",
    "                ST_MakePoint(\"Longitude\", \"Latitude\")::geography,\n",
    "                {radius} * 1609.34\n",
    "            ) AND \"Time\" BETWEEN '{start_date}' AND '{end_date}';\n",
    "    \"\"\"\n",
    "\n",
    "    # Read data into a GeoDataFrame\n",
    "    df_complaints = pd.read_sql_query(query_complaints, engine)\n",
    "    geometry_complaints = [shapely.geometry.Point(lon, lat) for lon, lat in zip(df_complaints['Longitude'], df_complaints['Latitude'])]\n",
    "    gdf_complaints = gpd.GeoDataFrame(df_complaints, geometry=geometry_complaints, crs='EPSG:4326')\n",
    "\n",
    "    # Plot the map\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    gdf_complaints.plot(ax=ax, color='purple', label='311 Complaints', markersize=10, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "    ax.set_title(f'311 Complaints')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.legend()\n",
    "\n",
    "    # Add grid\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_latitude = 40.80737875669467\n",
    "center_longitude = -73.96253174434912\n",
    "radius = 0.5\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2023-09-30'\n",
    "plot_visual_5(engine, center_latitude, center_longitude, radius, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_6():\n",
    "    query_trees = \"\"\"\n",
    "        SELECT\n",
    "            \"ID\",\n",
    "            \"Latitude\",\n",
    "            \"Longitude\"\n",
    "        FROM\n",
    "            \"NYC_Tree\";\n",
    "    \"\"\"\n",
    "\n",
    "    query_311 = \"\"\"\n",
    "        SELECT\n",
    "            \"Latitude\",\n",
    "            \"Longitude\"\n",
    "        FROM\n",
    "            \"NYC_311\"\n",
    "        WHERE\n",
    "            \"ComplaintType\" = 'New Tree Request'\n",
    "            AND \"Time\" BETWEEN '2018-10-01' AND '2023-09-30';\n",
    "    \"\"\"\n",
    "\n",
    "    # Use Pandas to read the query results\n",
    "    df_trees = pd.read_sql_query(query_trees, engine)\n",
    "    df_311 = pd.read_sql_query(query_311, engine)\n",
    "\n",
    "    # Create GeoDataFrames with Point geometries\n",
    "    geometry_trees = [shapely.geometry.Point(lon, lat) for lon, lat in zip(df_trees['Longitude'], df_trees['Latitude'])]\n",
    "    gdf_trees = gpd.GeoDataFrame(df_trees, geometry=geometry_trees, crs='EPSG:4326')\n",
    "\n",
    "    geometry_311 = [shapely.geometry.Point(lon, lat) for lon, lat in zip(df_311['Longitude'], df_311['Latitude'])]\n",
    "    gdf_311 = gpd.GeoDataFrame(df_311, geometry=geometry_311, crs='EPSG:4326')\n",
    "\n",
    "    return gdf_trees, gdf_311\n",
    "\n",
    "\n",
    "def plot_visual_6(gdf_trees, gdf_311):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    gdf_trees.plot(ax=ax, color='green', edgecolor='black', label='Trees', markersize=10)\n",
    "    gdf_311.plot(ax=ax, color='red', edgecolor='black', label='New Tree Requests', marker='s', markersize=10)\n",
    "\n",
    "    ax.set_title('Geospatial Plot of Trees and New Tree Requests')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_trees, gdf_311 = get_data_for_visual_6()\n",
    "plot_visual_6(gdf_trees, gdf_311)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
