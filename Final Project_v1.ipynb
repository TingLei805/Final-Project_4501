{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0750458",
   "metadata": {},
   "source": [
    "# NYC Apartment Search\n",
    "\n",
    "### Group Members: Ting Lei, Diwen Shi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf11fa0-4684-4f5e-8048-0f4cc5f4f243",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d51392",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f869ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = \"data\"\n",
    "ZIPCODE_DATA_FILE = DATA_DIR + \"/nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR + \"/zillow_rent_data.csv\"\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"Swia3cwdHIaSCmkBJBrjXKYaf\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/\"\n",
    "NYC_DATA_311 = BASE_NYC_DATA_URL + f\"resource/erm2-nwe9.csv?$$app_token={NYC_DATA_APP_TOKEN}&$select=created_date,incident_zip,latitude,longitude,complaint_type&$where=created_date BETWEEN '2022-10-01T00:00:00.000' AND '2023-09-30T23:59:59.999'&$limit=999999999\"\n",
    "NYC_DATA_TREES = BASE_NYC_DATA_URL + f\"api/views/5rq2-4hqu/rows.csv?$$app_token={NYC_DATA_APP_TOKEN}\"\n",
    "NYC_DATA_311_FILE = DATA_DIR + \"/311.csv\"\n",
    "NYC_DATA_TREE_FILE = DATA_DIR + \"/tree.csv\"\n",
    "\n",
    "\n",
    "DB_NAME = \"DataEda\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PW = \"postgres\" # password\n",
    "DB_URL = f\"postgresql+psycopg2://{DB_USER}:{DB_PW}@localhost:5432/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = \"queries\"\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(QUERY_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464a7d95",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151b785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_311_tree_data():\n",
    "    \"\"\"\n",
    "    This is a function to download data programmatically.\n",
    "\n",
    "    If 311/tree file directory does not exist, this function will create a new file \n",
    "    under this directory using request method.\n",
    "\n",
    "    Parameters:\n",
    "    Does not have any parameters.\n",
    "\n",
    "    Returns:\n",
    "    No returns but simply generate two text files containing data.\n",
    "    \"\"\"\n",
    "    print(\"downloading\")\n",
    "    if not os.path.exists(NYC_DATA_311_FILE):\n",
    "        response311 = requests.get(NYC_DATA_311)\n",
    "        if response311.status_code == 200:\n",
    "            with open(NYC_DATA_311_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(response311.text)\n",
    "        else:\n",
    "            raise Exception(\"Fail\")\n",
    "\n",
    "    if not os.path.exists(NYC_DATA_TREE_FILE):\n",
    "        responsetree = requests.get(NYC_DATA_TREES)\n",
    "        if responsetree.status_code == 200:\n",
    "            with open(NYC_DATA_TREE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(responsetree.text)\n",
    "        else:\n",
    "            raise Exception(\"Fail\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d2a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_311_tree_data():\n",
    "    \"\"\"\n",
    "    This is a function to read data into pandas dataframe.\n",
    "\n",
    "    Use a default pandas index and specify incident_zip column as string type, also drop\n",
    "    all rows that contain nan data and rename all imperative columns.\n",
    "\n",
    "    Parameters:\n",
    "    Does not have any parameters.\n",
    "\n",
    "    Returns:\n",
    "    311 and tree census dataframes.\n",
    "    \"\"\"\n",
    "    data_311 = pd.read_csv(NYC_DATA_311_FILE, index_col=None, dtype={\"incident_zip\":str}) \\\n",
    "            .dropna() \\\n",
    "            .rename(columns={\"created_date\": \"Time\", \"incident_zip\": \"ZipCode\", \"latitude\": \"Latitude\", \"longitude\": \"Longitude\", \"complaint_type\":\"ComplaintType\"})\n",
    "\n",
    "    data_tree = pd.read_csv(NYC_DATA_TREE_FILE, index_col=None, dtype={\"zipcode\": str}) \\\n",
    "        [[\"tree_id\", \"zipcode\", \"Latitude\", \"longitude\", \"spc_latin\", \"status\", \"health\"]] \\\n",
    "        .rename(columns={\"tree_id\": \"ID\", \"zipcode\": \"ZipCode\", \"longitude\": \"Longitude\", \"spc_latin\": \"Species\", \"status\": \"Status\", \"health\": \"Health\"}) \\\n",
    "        .dropna()\n",
    "\n",
    "    return data_311, data_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fadfdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile):\n",
    "    \"\"\"a function of which paramter is the file directory of zipcode datafile and returns a geometry datafile\"\"\"\n",
    "    nyc_shp = gpd.read_file(zipcode_datafile).to_crs(epsg=4326)\n",
    "    return nyc_shp\n",
    "\n",
    "def load_and_clean_zillow_data(zl_file):\n",
    "    \"\"\"a function of which paramter is the file directory of zillow data and returns a datafile\"\"\"\n",
    "    zillow = pd.read_csv(zl_file, index_col=None)\n",
    "    def expand_row(row):\n",
    "        value = row[9:]\n",
    "        df = pd.DataFrame({\"Time\": value.index, \"Rent\": value.values, \"ZipCode\": row[\"RegionName\"]})\n",
    "        return df\n",
    "    zillow = pd.concat(zillow.apply(expand_row, axis=1).tolist(), ignore_index=True).dropna()\n",
    "    return zillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7638d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    download_311_tree_data()\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    geodf_311_data,geodf_tree_data = load_311_tree_data()\n",
    "    df_zillow_data = load_and_clean_zillow_data(zl_file=ZILLOW_DATA_FILE)\n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        df_zillow_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa16ec99",
   "metadata": {},
   "source": [
    "_Downloading all the data we need in subsequent tasks_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbb7cb8",
   "metadata": {},
   "source": [
    "_Show basic info about each dataframe and show first 5 entries about each dataframe_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c0e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a95b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd765b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df43fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b1774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61282a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55175f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2730aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "def setup_new_postgis_database(username, db_name):\n",
    "    \"\"\"Using SQL to create a new database and enable postgis extension\"\"\"\n",
    "    try:\n",
    "        connection = psycopg2.connect(user=username,password=DB_PW)\n",
    "        connection.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "\n",
    "        with connection.cursor() as cursor:\n",
    "            create_db_query = sql.SQL(\"CREATE DATABASE {}\").format(sql.Identifier(db_name))\n",
    "            cursor.execute(create_db_query)\n",
    "\n",
    "        print(f\"Database '{db_name}' created successfully!\")\n",
    "\n",
    "        connection.close()\n",
    "        connection = psycopg2.connect(user=username, password=DB_PW,database=db_name)\n",
    "        connection.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        with connection.cursor() as cursor:\n",
    "            create_extension_query = \"CREATE EXTENSION IF NOT EXISTS postgis;\"\n",
    "            cursor.execute(create_extension_query)\n",
    "\n",
    "        print(\"PostGIS extension enabled successfully!\")\n",
    "\n",
    "    except (Exception, psycopg2.Error) as error:\n",
    "        print(f\"Error while setting up database: {error}\")\n",
    "\n",
    "    finally:\n",
    "        if connection:\n",
    "            connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_new_postgis_database(DB_USER, DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZIPCODE_SCHEMA = \"\"\"\n",
    "DROP TABLE IF EXISTS \"public\".\"ZipCode\";\n",
    "CREATE TABLE \"public\".\"ZipCode\" (\n",
    "  \"ZIPCODE\" text COLLATE \"pg_catalog\".\"default\",\n",
    "  \"BLDGZIP\" text COLLATE \"pg_catalog\".\"default\",\n",
    "  \"PO_NAME\" text COLLATE \"pg_catalog\".\"default\",\n",
    "  \"POPULATION\" float8,\n",
    "  \"AREA\" float8,\n",
    "  \"STATE\" text COLLATE \"pg_catalog\".\"default\",\n",
    "  \"COUNTY\" text COLLATE \"pg_catalog\".\"default\",\n",
    "  \"ST_FIPS\" text COLLATE \"pg_catalog\".\"default\",\n",
    "  \"CTY_FIPS\" text COLLATE \"pg_catalog\".\"default\",\n",
    "  \"URL\" text COLLATE \"pg_catalog\".\"default\",\n",
    "  \"SHAPE_AREA\" float8,\n",
    "  \"SHAPE_LEN\" float8,\n",
    "  \"geometry\" \"public\".\"geometry\"\n",
    ")\n",
    ";\n",
    "\n",
    "CREATE INDEX \"idx_ZipCode_geometry\" ON \"public\".\"ZipCode\" USING gist (\n",
    "  \"geometry\" \"public\".\"gist_geometry_ops_2d\"\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "NYC_311_SCHEMA = \"\"\"\n",
    "DROP TABLE IF EXISTS \"public\".\"NYC_311\";\n",
    "CREATE TABLE \"public\".\"NYC_311\" (\n",
    "  \"ZipCode\" varchar(10) COLLATE \"pg_catalog\".\"default\" NOT NULL,\n",
    "  \"Time\" date NOT NULL,\n",
    "  \"Latitude\" float8,\n",
    "  \"Longitude\" float8,\n",
    "  \"ComplaintType\" varchar(255) COLLATE \"pg_catalog\".\"default\"\n",
    ")\n",
    ";\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "NYC_TREE_SCHEMA = \"\"\"\n",
    "DROP TABLE IF EXISTS \"public\".\"NYC_Tree\";\n",
    "CREATE TABLE \"public\".\"NYC_Tree\" (\n",
    "  \"ID\" int8 NOT NULL,\n",
    "  \"ZipCode\" varchar(10) COLLATE \"pg_catalog\".\"default\",\n",
    "  \"Longitude\" float8,\n",
    "  \"Latitude\" float8,\n",
    "  \"Species\" varchar(255) COLLATE \"pg_catalog\".\"default\",\n",
    "  \"Status\" varchar(255) COLLATE \"pg_catalog\".\"default\",\n",
    "  \"Health\" varchar(255) COLLATE \"pg_catalog\".\"default\"\n",
    ")\n",
    ";\n",
    "\n",
    "ALTER TABLE \"public\".\"NYC_Tree\" ADD CONSTRAINT \"Tree_pkey\" PRIMARY KEY (\"ID\");\n",
    "\"\"\"\n",
    "\n",
    "ZILLOW_SCHEMA = \"\"\"\n",
    "DROP TABLE IF EXISTS \"public\".\"Zillow\";\n",
    "CREATE TABLE \"public\".\"Zillow\" (\n",
    "  \"ZipCode\" varchar(10) COLLATE \"pg_catalog\".\"default\" NOT NULL,\n",
    "  \"Time\" date NOT NULL,\n",
    "  \"Rent\" float4\n",
    ")\n",
    ";\n",
    "\n",
    "ALTER TABLE \"public\".\"Zillow\" ADD CONSTRAINT \"Rent_pkey\" PRIMARY KEY (\"ZipCode\", \"Time\");\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DB_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(ZIPCODE_SCHEMA)\n",
    "    f.write(NYC_311_SCHEMA)\n",
    "    f.write(NYC_TREE_SCHEMA)\n",
    "    f.write(ZILLOW_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "with engine.connect() as connection:\n",
    "    with open(\"schema.sql\", 'r') as file:\n",
    "        sql_script = text(file.read())\n",
    "        connection.execute(sql_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Data to Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablename_to_dataframe = {\n",
    "    \"ZipCode\": geodf_zipcode_data,\n",
    "    \"NYC_311\": geodf_311_data,\n",
    "    \"NYC_Tree\": geodf_tree_data,\n",
    "    \"Zillow\": df_zillow_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data.to_postgis('ZipCode', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.to_sql('NYC_Tree', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.to_sql('NYC_311', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.to_sql('Zillow', engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
